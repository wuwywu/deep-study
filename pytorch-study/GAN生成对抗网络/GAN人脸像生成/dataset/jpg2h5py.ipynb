{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CelebA 人脸图像数据下载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下载\n",
    "# mnist_dataset = torchvision.datasets.CelebA(root='.', download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import zipfile\n",
    "import imageio.v3 as iio\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images done ..  1000\n",
      "images done ..  2000\n",
      "images done ..  3000\n",
      "images done ..  4000\n",
      "images done ..  5000\n",
      "images done ..  6000\n",
      "images done ..  7000\n",
      "images done ..  8000\n",
      "images done ..  9000\n",
      "images done ..  10000\n",
      "images done ..  11000\n",
      "images done ..  12000\n",
      "images done ..  13000\n",
      "images done ..  14000\n",
      "images done ..  15000\n",
      "images done ..  16000\n",
      "images done ..  17000\n",
      "images done ..  18000\n",
      "images done ..  19000\n",
      "images done ..  20000\n"
     ]
    }
   ],
   "source": [
    "# 生成分成结构数据格式\n",
    "hdf5_file = r\".//celeba//celeba_aligned_small.h5py\"\n",
    "celebadat = r\".//celeba//img_align_celeba.zip\"\n",
    "# print(os.path.exists(celebadat))\n",
    "# 从 202,599 个图像中提取一部分图像进行训练\n",
    "total_images = 20000    # 设定训练数据集的大小\n",
    "if not os.path.exists(hdf5_file):\n",
    "    with h5py.File(hdf5_file, \"w\") as hf:\n",
    "\n",
    "        count = 0\n",
    "\n",
    "        with zipfile.ZipFile(celebadat, \"r\") as zf:\n",
    "            # ofile = zf.extract(\"img_align_celeba/000001.jpg\")\n",
    "            # img = imageio.imread(ofile)\n",
    "            \n",
    "            for i in zf.namelist():\n",
    "                # print(i)\n",
    "                if i[-4:] == \".jpg\":\n",
    "                    ofile = zf.extract(i)   # 解压单个文件，返回文件绝对路劲\n",
    "                    img = iio.imread(ofile) # 读取文件数据\n",
    "                    os.remove(ofile)        # 移除文件 \n",
    "\n",
    "                    count += 1\n",
    "                    \n",
    "                    # 创建一个数据集用gzip方式压缩，compression_opts设置--越大压缩越多\n",
    "                    hf.create_dataset('img_align_celeba/'+str(count)+'.jpg', data=img, compression=\"gzip\", compression_opts=9)\n",
    "                    \n",
    "                    \n",
    "\n",
    "                    if (count%1000 == 0):\n",
    "                        print(\"images done .. \", count)\n",
    "\n",
    "                    if (count == total_images):\n",
    "                        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[253., 231., 194.],\n",
      "         [253., 231., 194.],\n",
      "         [253., 231., 194.],\n",
      "         ...,\n",
      "         [246., 228., 216.],\n",
      "         [255., 237., 223.],\n",
      "         [254., 238., 222.]],\n",
      "\n",
      "        [[253., 231., 194.],\n",
      "         [253., 231., 194.],\n",
      "         [253., 231., 194.],\n",
      "         ...,\n",
      "         [248., 230., 218.],\n",
      "         [255., 237., 223.],\n",
      "         [254., 238., 222.]],\n",
      "\n",
      "        [[253., 231., 194.],\n",
      "         [253., 231., 194.],\n",
      "         [253., 231., 194.],\n",
      "         ...,\n",
      "         [250., 232., 220.],\n",
      "         [255., 238., 224.],\n",
      "         [255., 239., 223.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[140.,  74.,  26.],\n",
      "         [115.,  49.,   1.],\n",
      "         [146.,  78.,  33.],\n",
      "         ...,\n",
      "         [122.,  55.,  28.],\n",
      "         [123.,  56.,  30.],\n",
      "         [122.,  56.,  30.]],\n",
      "\n",
      "        [[130.,  62.,  15.],\n",
      "         [138.,  70.,  23.],\n",
      "         [166.,  98.,  53.],\n",
      "         ...,\n",
      "         [118.,  49.,  20.],\n",
      "         [120.,  50.,  24.],\n",
      "         [118.,  51.,  24.]],\n",
      "\n",
      "        [[168., 100.,  53.],\n",
      "         [204., 136.,  89.],\n",
      "         [245., 177., 132.],\n",
      "         ...,\n",
      "         [118.,  49.,  20.],\n",
      "         [120.,  50.,  24.],\n",
      "         [120.,  50.,  24.]]])\n"
     ]
    }
   ],
   "source": [
    "f = h5py.File(hdf5_file, \"r\")\n",
    "plt.imshow(np.array(f[\"img_align_celeba\"][\"1.jpg\"]))\n",
    "# print(torch.FloatTensor(np.array(f[\"img_align_celeba\"][\"1.jpg\"])))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
