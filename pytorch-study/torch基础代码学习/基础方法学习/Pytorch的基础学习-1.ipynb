{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入包\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1、数据类型\n",
    "    int                     IntTensor\n",
    "    float                   FloatTensor\n",
    "    int array               IntTensor[d1,d2,...]\n",
    "    float array             FloatTensor[d1,d2,...]\n",
    "    string                  使用编码的方式表示string类型"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# from_numpy()\n",
    "使用 from_numpy() 将 numpy 数据转化为 tensor    \n",
    "默认为torch.float64类型 torch.DoubleTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.0000, 3.4000], dtype=torch.float64)\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# import from numpy\n",
    "a = np.array([2,3.4])\n",
    "a = torch.from_numpy(a)\n",
    "print(a)\n",
    "b = np.ones([2,3])\n",
    "b = torch.from_numpy(b)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.0000, 3.2000]) torch.FloatTensor\n",
      "tensor([[2.0000, 3.2000],\n",
      "        [1.0000, 2.2000]]) torch.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "# import from list\n",
    "a = torch.tensor([2., 3.2])\n",
    "print(a, a.type())\n",
    "b = torch.tensor([[2,3.2], [1,2.2]])\n",
    "print(b, b.type())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# empty, Tensor, IntTensor, FloatTensor的应用\n",
    "torch.Tensor()是python类-----------torch.FloatTensor    \n",
    "torch.tensor()是python函数  \n",
    "Tensor()接收维度， tensor()接收数据     \n",
    "效果差不多，用法有一定的区别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[8.4490e-39, 1.0194e-38, 8.9082e-39, 8.4490e-39]]) torch.FloatTensor\n",
      "tensor([[9.3674e-39, 1.0929e-38, 1.0469e-38],\n",
      "        [8.4490e-39, 1.1112e-38, 9.5511e-39]]) torch.FloatTensor\n",
      "tensor([1, 2, 3]) torch.LongTensor\n"
     ]
    }
   ],
   "source": [
    "# 初始化数据的函数\n",
    "a = torch.empty(1,4)\n",
    "print(a, a.type()) \n",
    "b = torch.Tensor(2,3)   # 随机\n",
    "print(b, b.type())\n",
    "c = torch.tensor((1,2,3))\n",
    "print(c, c.type())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 改变默认数据类型 \n",
    "PyTorch的默认类型是FloatTensor  \n",
    "使用set_default_tensor_type()改变默认数据类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.FloatTensor\n",
      "torch.DoubleTensor\n"
     ]
    }
   ],
   "source": [
    "print(torch.tensor([1.2, 3]).type())\n",
    "torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "print(torch.tensor([1.2, 3]).type())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 切片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 5, 6])\n",
      "torch.Size([2, 5, 6])\n",
      "tensor([0.7179, 0.7893, 0.5474, 0.6799, 0.7482, 0.7231, 0.5528, 0.6830, 0.7312,\n",
      "        0.9746, 0.8010, 0.5123, 0.7358, 0.6829, 0.6521, 0.9753, 0.9356, 0.9375,\n",
      "        0.9403, 0.7518, 0.6224, 0.5517, 0.7748, 0.7679, 0.6387, 0.6818, 0.5453,\n",
      "        0.7594, 0.8017, 0.5390, 0.8013, 0.6187, 0.5144, 0.7044, 0.7314, 0.8759,\n",
      "        0.7842, 0.6881, 0.8244, 0.6899, 0.9117, 0.6755, 0.7291, 0.7848, 0.8143,\n",
      "        0.5004, 0.8892, 0.8549, 0.6589, 0.8626, 0.9132, 0.6851, 0.6785, 0.9860,\n",
      "        0.5624, 0.7200, 0.7185, 0.8171, 0.9923, 0.9549, 0.9051, 0.5911, 0.9679,\n",
      "        0.5334])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(4,5,6)\n",
    "print(a.shape)\n",
    "b = a[0:3:2,:,:]\n",
    "print(b.shape)\n",
    "print(a[a>0.5])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 维度变换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.9287, 0.9168],\n",
      "         [0.1065, 0.7998],\n",
      "         [0.9451, 0.0527]],\n",
      "\n",
      "        [[0.1955, 0.6370],\n",
      "         [0.7330, 0.3460],\n",
      "         [0.7503, 0.0587]],\n",
      "\n",
      "        [[0.2362, 0.0986],\n",
      "         [0.0872, 0.6687],\n",
      "         [0.4625, 0.8354]],\n",
      "\n",
      "        [[0.0654, 0.6410],\n",
      "         [0.9370, 0.1740],\n",
      "         [0.0156, 0.1133]]])\n",
      "tensor([[0.9287, 0.9168, 0.1065, 0.7998, 0.9451, 0.0527],\n",
      "        [0.1955, 0.6370, 0.7330, 0.3460, 0.7503, 0.0587],\n",
      "        [0.2362, 0.0986, 0.0872, 0.6687, 0.4625, 0.8354],\n",
      "        [0.0654, 0.6410, 0.9370, 0.1740, 0.0156, 0.1133]])\n"
     ]
    }
   ],
   "source": [
    "# 使用view变换维度\n",
    "a = torch.rand(4,3,2)\n",
    "print(a)\n",
    "\n",
    "b = a.view(4, 3*2)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 3, 2])\n",
      "torch.Size([4, 1, 3, 2])\n",
      "torch.Size([4, 3, 2, 1])\n",
      "torch.Size([4, 3, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "# 使用 unsqueeze 增维\n",
    "# unsqueeze(x) 再x位置上插入一个维度\n",
    "print(a.unsqueeze(0).shape)\n",
    "print(a.unsqueeze(1).shape)\n",
    "print(a.unsqueeze(-1).shape)\n",
    "print(a.unsqueeze(-2).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 1, 1])\n",
      "torch.Size([4, 3, 1, 1])\n",
      "torch.Size([4, 3, 1])\n",
      "torch.Size([4, 3, 1])\n",
      "torch.Size([4, 3])\n"
     ]
    }
   ],
   "source": [
    "# 使用 unsqueeze 降维(不包含参数的维度)\n",
    "a = torch.rand(4,3,1,1)\n",
    "print(a.squeeze(0).shape)\n",
    "print(a.squeeze(1).shape)\n",
    "print(a.squeeze(2).shape)\n",
    "print(a.squeeze(3).shape)\n",
    "print(a.squeeze(2).squeeze(2).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.5900],\n",
      "         [0.7323]],\n",
      "\n",
      "        [[0.7051],\n",
      "         [0.2751]],\n",
      "\n",
      "        [[0.3165],\n",
      "         [0.9685]],\n",
      "\n",
      "        [[0.5393],\n",
      "         [0.9983]]])\n",
      "tensor([[[0.5900, 0.5900],\n",
      "         [0.7323, 0.7323]],\n",
      "\n",
      "        [[0.7051, 0.7051],\n",
      "         [0.2751, 0.2751]],\n",
      "\n",
      "        [[0.3165, 0.3165],\n",
      "         [0.9685, 0.9685]],\n",
      "\n",
      "        [[0.5393, 0.5393],\n",
      "         [0.9983, 0.9983]]])\n"
     ]
    }
   ],
   "source": [
    "# 使用 expand 扩展维度(扩张维度为1的位置)\n",
    "a = torch.rand(4,2,1)\n",
    "print(a)\n",
    "print(a.expand(4,2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8370, 0.6487],\n",
      "        [0.3538, 0.6472]])\n",
      "tensor([[0.8370, 0.6487, 0.8370, 0.6487],\n",
      "        [0.3538, 0.6472, 0.3538, 0.6472],\n",
      "        [0.8370, 0.6487, 0.8370, 0.6487],\n",
      "        [0.3538, 0.6472, 0.3538, 0.6472]])\n",
      "tensor([[0.8370, 0.6487, 0.8370, 0.6487],\n",
      "        [0.3538, 0.6472, 0.3538, 0.6472],\n",
      "        [0.8370, 0.6487, 0.8370, 0.6487],\n",
      "        [0.3538, 0.6472, 0.3538, 0.6472],\n",
      "        [0.8370, 0.6487, 0.8370, 0.6487],\n",
      "        [0.3538, 0.6472, 0.3538, 0.6472],\n",
      "        [0.8370, 0.6487, 0.8370, 0.6487],\n",
      "        [0.3538, 0.6472, 0.3538, 0.6472]])\n"
     ]
    }
   ],
   "source": [
    "# 使用 repeat 扩展维度\n",
    "a = torch.rand(2,2)\n",
    "print(a)\n",
    "print(a.repeat(2,2))\n",
    "print(a.repeat(2*2,2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 拼接与拆分 --- Cat, Stack, Split, Chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7982, 0.5251],\n",
      "        [0.6214, 0.0242]]) tensor([[0.0729, 0.7673],\n",
      "        [0.0245, 0.8730]])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([4, 2])\n",
      "torch.Size([2, 2, 2])\n",
      "torch.Size([2, 2, 2])\n",
      "(tensor([[0.7982],\n",
      "        [0.6214]]), tensor([[0.5251],\n",
      "        [0.0242]]))\n",
      "(tensor([[0.7982, 0.5251]]), tensor([[0.6214, 0.0242]]))\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(2,2)\n",
    "b = torch.rand(2,2)\n",
    "print(a, b)\n",
    "print(torch.cat([a, b], dim=1).shape)\n",
    "print(torch.cat([a, b], dim=0).shape)\n",
    "print(torch.stack([a, b], dim=0).shape)\n",
    "print(torch.stack([a, b], dim=1).shape)\n",
    "print(a.split(1, dim=1))\n",
    "print(a.chunk(2, dim=0))    # 等量分割"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch 的基本数学运算\n",
    "## 数学运算\n",
    "Add/minus/multiply/divide   \n",
    "Matmul  \n",
    "Pow     \n",
    "Sqrt/rsqrt  \n",
    "Round\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1932, 0.0082, 0.3093, 0.0657],\n",
      "        [0.0753, 0.0833, 0.1849, 0.3216],\n",
      "        [0.1672, 0.2167, 0.3714, 0.6963]]) \n",
      " tensor([0.5981, 0.9489, 0.4039, 0.4655])\n",
      "tensor([[0.7913, 0.9571, 0.7132, 0.5312],\n",
      "        [0.6734, 1.0321, 0.5888, 0.7871],\n",
      "        [0.7653, 1.1655, 0.7753, 1.1619]])\n",
      "tensor([[0.7913, 0.9571, 0.7132, 0.5312],\n",
      "        [0.6734, 1.0321, 0.5888, 0.7871],\n",
      "        [0.7653, 1.1655, 0.7753, 1.1619]])\n"
     ]
    }
   ],
   "source": [
    "# add 加\n",
    "a = torch.rand(3,4)\n",
    "b = torch.rand(4)\n",
    "print(a, \"\\n\", b)\n",
    "print(a+b)\n",
    "print(torch.add(a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4049, -0.9406, -0.0946, -0.3999],\n",
      "        [-0.5228, -0.8656, -0.2191, -0.1440],\n",
      "        [-0.4309, -0.7322, -0.0325,  0.2308]])\n",
      "tensor([[0.1156, 0.0078, 0.1249, 0.0306],\n",
      "        [0.0451, 0.0790, 0.0747, 0.1497],\n",
      "        [0.1000, 0.2056, 0.1500, 0.3242]])\n",
      "tensor([[0.3231, 0.0087, 0.7657, 0.1410],\n",
      "        [0.1260, 0.0877, 0.4576, 0.6907],\n",
      "        [0.2795, 0.2283, 0.9195, 1.4958]])\n"
     ]
    }
   ],
   "source": [
    "# sub 减；mul 乘；div 除\n",
    "print(torch.sub(a,b))\n",
    "print(torch.mul(a,b))\n",
    "print(torch.div(a,b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eq(a-b, torch.sub(a,b))\n",
    "torch.all(torch.eq(a-b, torch.sub(a,b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.1722]])\n",
      "tensor([[1.1722]])\n"
     ]
    }
   ],
   "source": [
    "# 矩阵相乘 matmul --- 另一种写法：@\n",
    "a = torch.rand(1,4)\n",
    "b = torch.rand(4,1)\n",
    "print(torch.matmul(a,b))\n",
    "print(a@b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9, 9, 9],\n",
      "        [9, 9, 9]])\n",
      "tensor([[9, 9, 9],\n",
      "        [9, 9, 9]])\n"
     ]
    }
   ],
   "source": [
    "# Power exp log\n",
    "# sqrt ,rsqrt\n",
    "a = torch.full([2,3],3)\n",
    "print(a.pow(2))\n",
    "print(a**2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 统计性质\n",
    "norm----范数        \n",
    "mean_sum    \n",
    "prod----所有元素的积    \n",
    "max, min, argmin, argmax    \n",
    "kthvalue, topk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 2., 3.],\n",
      "        [4., 5., 6., 7.]], dtype=torch.float32)\n",
      "tensor(0., dtype=torch.float32) tensor(7., dtype=torch.float32) tensor(3.5000, dtype=torch.float32) tensor(0., dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "a = torch.arange(8).view(2,4).type(torch.FloatTensor)\n",
    "print(a)\n",
    "print(a.min(), a.max(), a.mean(), a.prod())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1111\n",
      "111111111\n"
     ]
    }
   ],
   "source": [
    "# 类中__call__的使用\n",
    "class test:\n",
    "    def __init__(self, a):\n",
    "        print(a)\n",
    "        pass\n",
    "    def __call__(self, b):\n",
    "        print(b)\n",
    "        pass\n",
    "c = test(1111)\n",
    "\n",
    "c(111111111)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# where 和 gather操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0246, 0.2971],\n",
      "        [0.2750, 0.8281]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 1.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# where\n",
    "# torch.where(condition, x, y)\n",
    "cond = torch.rand(2,2)\n",
    "print(cond)\n",
    "a = torch.ones(2,2)\n",
    "b = torch.zeros(2,2)\n",
    "torch.where(cond>0.5, a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([100, 101, 102, 103, 104, 105, 106, 107, 108, 109])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[101, 101, 102],\n",
       "        [101, 102, 103],\n",
       "        [101, 104, 103],\n",
       "        [100, 105, 103]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gather搜集\n",
    "# torch.gather(input, dim, index, out=None)\n",
    "a = torch.arange(10)+100\n",
    "print(a)\n",
    "torch.gather(a.expand(4,10), dim=1, index=torch.tensor([[1,1,2],[1,2,3],[1,4,3],[0,5,3]]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch 自动求导\n",
    "1、创建求导变量，在创建张量时 requires_grad=True    \n",
    "2、使用 backward() 求出导数（梯度）或者使用 autograd.grad() 求出导数（梯度）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.]])\n",
      "tensor([[5., 5., 5.]])\n",
      "tensor(16., grad_fn=<MseLossBackward0>)\n",
      "(tensor([[2.6667, 2.6667, 2.6667]]),)\n",
      "tensor([[2.6667, 2.6667, 2.6667]])\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import functional as F\n",
    "x = torch.ones([1,3])\n",
    "# x = torch.tensor([1,2])\n",
    "print(x)\n",
    "# w = torch.full([1],5., requires_grad=True)\n",
    "w = torch.full([1,3],5.)\n",
    "print(w)\n",
    "w.requires_grad_()\n",
    "mse = F.mse_loss(torch.ones([1,3]), x*w)\n",
    "print(mse)\n",
    "\n",
    "# 使用 autograd.grad() 求导\n",
    "# 使用 retain_graph 可保留图（每次求导，图被清除，必须再次建立，使用retain_graph可保留图到下次求导）\n",
    "a = torch.autograd.grad(mse, [w], retain_graph=True)\n",
    "print(a)\n",
    "\n",
    "# 使用 backward() 求导\n",
    "mse.backward()\n",
    "print(w.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1, 11,  3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 1, 11,  3])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.tensor([-1,2,3])\n",
    "b=torch.tensor([3,2,3])\n",
    "a[1] = 11\n",
    "print(a)\n",
    "torch.where((a>1)&(b<3))\n",
    "\n",
    "torch.abs(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 2.],\n",
      "        [2., 2.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(2,2)\n",
    "a[:]=2\n",
    "print(a)\n",
    "# print(torch.pow(a,2))\n",
    "# (a.T).repeat(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5000])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.full([1], 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'>\n"
     ]
    }
   ],
   "source": [
    "def test1(a=2):\n",
    "    print(type(a))\n",
    "\n",
    "test1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2]\n"
     ]
    }
   ],
   "source": [
    "a = list([])\n",
    "a.append(1)\n",
    "a.append(2)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    print(\"1\")\n",
    "\n",
    "a = test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
